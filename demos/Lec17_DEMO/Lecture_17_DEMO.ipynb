{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 17 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## Alameda County Jury Panels ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These data are from 2010, Alameda County, California\n",
    "# The 'Panels' values are based on the actual jury panel of 1423 eligible jurors\n",
    "jury = Table().with_columns(\n",
    "    'Ethnicity', make_array('Asian', 'Black', 'Latino', 'White', 'Other'),\n",
    "    'Eligible', make_array(0.15, 0.18, 0.12, 0.54, 0.01),\n",
    "    'Panels', make_array(0.26, 0.08, 0.08, 0.54, 0.04)\n",
    ")\n",
    "\n",
    "jury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the actual jury panel proportions are different from the proportions in the eligible population. Our job is to assess whether this difference could be due to just random variation, or is it extreme enough to show that the panel selection process is biased in some way?\n",
    "\n",
    "Here's a visualization of the actual panel proportions along with the eligible population proportions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jury.barh('Ethnicity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Under the model (null hypothesis states that jury panel selection is not biased), this is \n",
    "# the true distribution from which jury panels are formed, supposedly at random\n",
    "model = make_array(0.15, 0.18, 0.12, 0.54, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate data based on the model\n",
    "\n",
    "We use `sample_proportions` to simulate the results of random sampling for a categorical variable such as 'Ethnicity':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's simulate a random draw of 1423 jurors from this distribution\n",
    "def simulated(): \n",
    "    ''' returns the proportions from a simulated sample of 1423 jurors\n",
    "        using the model distribution\n",
    "    '''\n",
    "    sample_size = 1423  # to match the real-world jury panel data\n",
    "    ...\n",
    "\n",
    "simulated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual observed distribution (Panels) looks quite different\n",
    "# from the simulation -- try running this several times to confirm!\n",
    "jury_with_simulated = jury.with_column('Simulated', simulated())\n",
    "jury_with_simulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jury_with_simulated.barh('Ethnicity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: When we create simulated proportions many times, based on the model, do we find that the real-world sample is consistent with the model? What statistic will we use to make this assessment?\n",
    "\n",
    "A statistic is a single number. If we want to describe how far the 'Panel' proportions are from the 'Eligible', for example, what arithmetic will we use?\n",
    "\n",
    "  - Plan A: To compare a column of values `(a, b, c, d, e)` with another column of values `(a2, b2, c2, d2, e2)`, we could sum up the pairwise differences: `(a-a2) + (b-b2) + (c-c2) + (d-d2) + (e-e2)`. Why is this NOT a good way to make a statistic for our specific context (Alameda jury panel selection)?\n",
    "\n",
    "  - Plan B: Total Variation Distance (TVD). Apply absolute values to each difference before adding, so that negative and positive differences don't cancel each other out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example showing Plan A is not feasible:\n",
    "vals1 = make_array(.3, .4, .1, .1, .1)  # sum is 1\n",
    "vals2 = make_array(.2, .3, 0, .1, .4)   # sum is 1\n",
    "total_deviation = np.sum(vals1 - vals2)\n",
    "total_deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Back to Slides...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Variation Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvd(dist1, dist2):\n",
    "    '''\n",
    "    Takes the proportions `dist1` and `dist2` for two categorical distributions \n",
    "        of the same length\n",
    "    Returns the Total Variation Distance between the distributions\n",
    "    '''\n",
    "    ...\n",
    "    return np.sum(np.abs(dist1 - dist2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The TVD of our observed data (Panels column) from their expected values,\n",
    "# assuming the model is true\n",
    "obsvd_tvd = ...\n",
    "obsvd_tvd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the observed TVD \"large\"? \n",
    "\n",
    "Does it indicate a biased jury panel selection process, or could it plausibly be the result of random variation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the TVD for one simulated jury pool of size 1423\n",
    "tvd(simulated(), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To truly understand the observed tvd in the context of the model, we need to\n",
    "# make many simulated distributions and collect up the resulting TVD values\n",
    "\n",
    "# One simulated test statistic:\n",
    "def simulated_tvd():\n",
    "    '''\n",
    "    Returns the TVD for one simulated jury pool of size 1423\n",
    "    '''\n",
    "    ...\n",
    "    return tvd(simulated(), model)\n",
    "\n",
    "# An empty array to collect up many simulated values:\n",
    "tvds = ...\n",
    "\n",
    "# A for loop to run the simulation 10000 times:\n",
    "num_simulations = ...\n",
    "num_simulations = 10000\n",
    "for ...\n",
    "   ...\n",
    "\n",
    "print(len(tvds))\n",
    "tvds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram for the simulated TVD values\n",
    "# We see that the TVD numbers tend to be between 0.00 and 0.10\n",
    "axis_label = 'Simulated TVDs (if model is true)'\n",
    "mybins = np.arange(0.0, 0.15, .005)\n",
    "\n",
    "tbl = Table().with_column(axis_label, tvds)\n",
    "tbl.hist(bins = mybins)\n",
    "print('Observed TVD: ' + str(obsvd_tvd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the observed TVD of 0.14 is WAY outside the realm of reasonability if the model is correct. We conclude that the jury pool formation process is not like random sampling and does not tend to result in a representative jury pool.\n",
    "\n",
    "**Back to Slides...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
